{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **In this notebook**, \n",
        "\n",
        "1.   Generating threads with full details\n",
        "2.   Sort the generated thread from root to leaf\n",
        "2.   Filtering out threads with no repeated of toxic author\n",
        "3.   Filtering out threads with gaps ( body == [removed] and Not found )\n",
        "4.   Filtering out tthreads by LangID\n",
        "6.   Generating threads with author, text, and permalink (for verification)\n",
        "5. Cleaning and Formating final json file according to offline protocol\n",
        "\n",
        "**Note:** I have broken down several actions in section, so that we can an action if the resultant threads are very less.\n",
        "Ex: while removing gaps in thread, a lot of threads get discarded, so that is why I am saving the threads at all points. Similarly for langID filter.\n",
        "\n",
        "**Note**: Make sure that the master log and removed comments are from the same time stamp\n",
        "\n"
      ],
      "metadata": {
        "id": "FCMtW54psunG"
      },
      "id": "FCMtW54psunG"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "x547LWZbtljV"
      },
      "id": "x547LWZbtljV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "528eNb_hauMO"
      },
      "source": [
        "# **Loading and processing master log for comments and posts and removed comments**"
      ],
      "id": "528eNb_hauMO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the [**Removed_com_collection_notebook**](https://colab.research.google.com/drive/1zialczWr7qdN9hfEatYIJpdk5kquCkWb?usp=sharing)\n",
        "\n",
        "You would get ***new_com_stream_{subreddit}_{timestamp}.csv file*** files which need to be uploaded here.\n",
        "\n",
        "For post stream you can upload the csv file directly downloaded from the server, as posts csv are small in size "
      ],
      "metadata": {
        "id": "2uoZ5VpQTmWH"
      },
      "id": "2uoZ5VpQTmWH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKamZ60W0MxH"
      },
      "outputs": [],
      "source": [
        "# from the removed_com_collection_notebook, the dataframe that is saved and downloaded after updating the removed and darma_author column\n",
        "master_log = pd.read_csv('/content/new_com_stream_france_15Aug2022_to_28Aug2022.csv')\n",
        "\n",
        "# downloaded from the server\n",
        "post_stream = pd.read_csv('/content/sub_stream_france.csv')\n",
        "\n",
        "# final_removed_df = pd.read_csv('/content/removed_com_science_20july_to_15aug.csv')"
      ],
      "id": "nKamZ60W0MxH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To check the schema of hte above dataframes\n",
        "\n"
      ],
      "metadata": {
        "id": "R6JOiPr1U7v9"
      },
      "id": "R6JOiPr1U7v9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhPrg627D1be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067f165d-bb21-4e13-959d-eb473eccbef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15862 entries, 0 to 15861\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   author        15862 non-null  object \n",
            " 1   created_utc   15862 non-null  float64\n",
            " 2   id            15862 non-null  object \n",
            " 3   num_comments  15862 non-null  float64\n",
            " 4   permalink     15862 non-null  object \n",
            " 5   score         15862 non-null  float64\n",
            " 6   selftext      6515 non-null   object \n",
            " 7   title         15862 non-null  object \n",
            " 8   upvote_ratio  15862 non-null  float64\n",
            "dtypes: float64(4), object(5)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "post_stream.info()"
      ],
      "id": "NhPrg627D1be"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6bj5xY1NoUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b09b44-0b86-4089-a293-156b493c0db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 77069 entries, 0 to 77068\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   author            77069 non-null  object \n",
            " 1   body              77069 non-null  object \n",
            " 2   collapsed         77069 non-null  float64\n",
            " 3   controversiality  77069 non-null  float64\n",
            " 4   created_utc       77069 non-null  float64\n",
            " 5   id                77069 non-null  object \n",
            " 6   link_id           77069 non-null  object \n",
            " 7   parent_id         77069 non-null  object \n",
            " 8   permalink         77069 non-null  object \n",
            " 9   score             77069 non-null  float64\n",
            " 10  removed           77069 non-null  bool   \n",
            " 11  darma_author      77069 non-null  object \n",
            "dtypes: bool(1), float64(4), object(7)\n",
            "memory usage: 6.5+ MB\n"
          ]
        }
      ],
      "source": [
        "master_log.info()"
      ],
      "id": "d6bj5xY1NoUl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check in above step, using info()**\n",
        "\n",
        "For **comment** log,\n",
        "\n",
        "> If the comment master log is loaded from **new_com_stream**... (i.e. from the **removed_com_collection_notebook**) it would have the **darma_author** and **removed** col, then you would **not require** to run the next few steps of **author mapping** and **removed column**.\n",
        "\n",
        "> Else, If in some case you have the **removed_com** file for a particular **timestamp** but do not have **new_com_stream**, then you can upload the **comment master log csv file** (com_stream) directly downloaded from the server and in that case, the next steps--**author mapping step** and **removed column** are **required**.\n",
        "(overhead is that it would be large file, hence many comparison to do while generating threads.)\n",
        "\n",
        "Although this case should not arrive if you have run the **removed_com_collection_notebook**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "For **post** log, author mapping step is **required**."
      ],
      "metadata": {
        "id": "TNtWED2YXCji"
      },
      "id": "TNtWED2YXCji"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Author mapping Step** if **darma_author** and **removed** col are not present in the comment stream"
      ],
      "metadata": {
        "id": "hWcpjxPN2QcW"
      },
      "id": "hWcpjxPN2QcW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXbEyBdQxNJl"
      },
      "outputs": [],
      "source": [
        "def map_author(input):\n",
        "  hash = hashlib.sha256()\n",
        "  hash.update(input.encode('utf-8'))\n",
        "  digested = hash.digest()\n",
        "  output_string = \"\"\n",
        "\n",
        "  for iter in range (0,8):\n",
        "      mod_result = ord(chr(digested[iter])) % 52\n",
        "      if mod_result < 26:\n",
        "          output_string += chr(65 + mod_result)\n",
        "      else:\n",
        "          mod_result -= 26\n",
        "          output_string += chr(97 + mod_result)\n",
        "  return output_string"
      ],
      "id": "GXbEyBdQxNJl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auhtor mapping for post stream is **required**"
      ],
      "metadata": {
        "id": "pg-jHURJ2Yl_"
      },
      "id": "pg-jHURJ2Yl_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whL48ogwE-6R"
      },
      "outputs": [],
      "source": [
        "post_stream['darma_author'] = post_stream['author'].apply(lambda x: map_author(x))"
      ],
      "id": "whL48ogwE-6R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating darma_author column if the **comment** master log is directly downloaded from the server"
      ],
      "metadata": {
        "id": "aXxKdEXb2eiK"
      },
      "id": "aXxKdEXb2eiK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRJXzVEkNxul"
      },
      "outputs": [],
      "source": [
        "# master_log['darma_author'] = master_log['author'].apply(lambda x: map_author(x))"
      ],
      "id": "BRJXzVEkNxul"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Removed column step** ONLY if the **comment** master log is directly downloaded from the server and you have the removec_com csv file"
      ],
      "metadata": {
        "id": "D1kxeTvD2nL2"
      },
      "id": "D1kxeTvD2nL2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkLHi-hLNxiP"
      },
      "outputs": [],
      "source": [
        "# master_log['removed'] = master_log['id'].isin(set(list(final_removed_df['id'])))"
      ],
      "id": "BkLHi-hLNxiP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finalizing Removed com dataframe from master_log so that it has darma_author and removed col**"
      ],
      "metadata": {
        "id": "ZSZLMnG65EbY"
      },
      "id": "ZSZLMnG65EbY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmPNRtFPSPNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2c99ca-fefd-4172-f2c4-4748e58b6f62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "655"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "removed_com = master_log[master_log['removed']==True]\n",
        "len(removed_com)"
      ],
      "id": "DmPNRtFPSPNr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ndWwx_vQpvt"
      },
      "source": [
        "# **Generate threads**\n",
        "This section takes a lot of time to generate"
      ],
      "id": "5ndWwx_vQpvt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noW-TRbOapZ8"
      },
      "source": [
        "### Connecting to Reddit API"
      ],
      "id": "noW-TRbOapZ8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCa5U7HPWbNh"
      },
      "outputs": [],
      "source": [
        "pip install praw"
      ],
      "id": "BCa5U7HPWbNh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "damaged-classics"
      },
      "outputs": [],
      "source": [
        "credentials = 'client_secret.json'\n",
        "\n",
        "with open(credentials) as f:\n",
        "    creds = json.load(f)"
      ],
      "id": "damaged-classics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "broad-saudi"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "reddit = praw.Reddit(client_id = creds['client_id'],\n",
        "                    client_secret = creds['client_secret'],\n",
        "                    user_agent = creds['user_agent'],\n",
        "                    redirect_uri = creds['redirect_uri'],\n",
        "                    refresh_token = creds['refresh_token'],\n",
        "                     check_for_async = False)"
      ],
      "id": "broad-saudi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for finding parent by comment ID"
      ],
      "metadata": {
        "id": "Zy7F1LvtBVFD"
      },
      "id": "Zy7F1LvtBVFD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsnE8B2yF09o"
      },
      "outputs": [],
      "source": [
        "# function which find parent post by id\n",
        "# first looks in the post stream\n",
        "# if not found, then fetchs it from reddit directly and appends in the post stream\n",
        "\n",
        "def find_parent_post(id):\n",
        "  global post_stream\n",
        "\n",
        "  if id in set(list(post_stream['id'])):\n",
        "    par_post = post_stream[post_stream['id']==id]\n",
        "    # print(\">>>post found in master\")\n",
        "    return par_post.to_dict('records')[0]\n",
        "\n",
        "  else:\n",
        "    parent_post = reddit.submission(id = str(id))\n",
        "\n",
        "    sub_dict = {}\n",
        "    sub_dict['id'] = parent_post.id\n",
        "    sub_dict['title'] = parent_post.title\n",
        "    sub_dict['selftext'] = parent_post.selftext\n",
        "    sub_dict['score'] = parent_post.score\n",
        "    sub_dict['upvote_ratio'] = parent_post.upvote_ratio\n",
        "    sub_dict['num_comments'] = parent_post.num_comments\n",
        "    sub_dict['permalink'] = parent_post.permalink\n",
        "    sub_dict['created_utc'] = parent_post.created_utc\n",
        "\n",
        "    try:\n",
        "      if parent_post.author != None:\n",
        "        sub_dict['author'] = parent_post.author.id\n",
        "        sub_dict['darma_author'] = map_author(parent_post.author.id)\n",
        "      else:\n",
        "        sub_dict['author'] = 'Not found'\n",
        "        sub_dict['darma_author'] = 'Not found'\n",
        "    except Exception as e:\n",
        "      print(\"Post Author ERROR: author is \", parent_post.author, \"Exception: \", e)\n",
        "      sub_dict['author'] = 'Not found'\n",
        "      sub_dict['darma_author'] = 'Not found'\n",
        "\n",
        "    df_dictionary = pd.DataFrame([sub_dict])\n",
        "    post_stream = pd.concat([post_stream, df_dictionary], ignore_index=True)\n",
        "\n",
        "    print(\">>>post Not found in master \", id)\n",
        "    return sub_dict"
      ],
      "id": "SsnE8B2yF09o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJTzZTBcjUtv"
      },
      "outputs": [],
      "source": [
        "# function which find parent comment by id\n",
        "# first looks in the comment stream\n",
        "# if not found, then fetchs it from reddit directly and appends in the comment stream\n",
        "\n",
        "def find_parent_com(par_id):\n",
        "  global master_log\n",
        "\n",
        "  if par_id in set(list(master_log['id'])):\n",
        "    par_com = master_log[master_log['id']==par_id]\n",
        "    c_dict = par_com.to_dict('records')[0]\n",
        "    c_dict['removed'] = 0 if c_dict['removed'] == False else 1\n",
        "    return c_dict\n",
        "    \n",
        "  else:\n",
        "    p = reddit.comment(id = par_id)\n",
        "    temp_dict = {}\n",
        "    temp_dict['id'] = p.id\n",
        "    temp_dict['parent_id'] = p.parent_id\n",
        "    temp_dict['link_id'] = p.link_id\n",
        "    temp_dict['body'] = p.body\n",
        "    temp_dict['collapsed'] = 0 if p.collapsed == False else 1\n",
        "    temp_dict['score'] = p.score\n",
        "    temp_dict['controversiality'] = p.controversiality\n",
        "    temp_dict['permalink'] = p.permalink\n",
        "    temp_dict['created_utc'] = p.created_utc\n",
        "\n",
        "    if p.body == '[removed]':\n",
        "      temp_dict['body'] =  '[removed] and NOT FOUND'\n",
        "      temp_dict['removed'] = True\n",
        "    else:\n",
        "      temp_dict['removed'] = False\n",
        "\n",
        "    try: \n",
        "      if p.author != None:\n",
        "        temp_dict['author'] = p.author.id\n",
        "        temp_dict ['darma_author'] = map_author(p.author.id)\n",
        "      else:\n",
        "        temp_dict ['author'] = 'Not found'\n",
        "        temp_dict['darma_author'] = 'Not found'\n",
        "    except Exception as e:\n",
        "      temp_dict ['author'] = 'Not found'\n",
        "      temp_dict['darma_author'] = 'Not found'\n",
        "      print(\"Comment Author ERROR: author is \", p.author, \"Exception: \", e)\n",
        "\n",
        "    df_com_dict = pd.DataFrame([temp_dict])\n",
        "    master_log = pd.concat([master_log, df_com_dict], ignore_index=True)\n",
        "\n",
        "    temp_dict['removed'] = 0 if temp_dict['removed'] == False else 1\n",
        "    print(\">>>comment Not found in master \", par_id)\n",
        "    return temp_dict"
      ],
      "id": "UJTzZTBcjUtv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rSUnS5Xn6lc"
      },
      "outputs": [],
      "source": [
        "# Generates and returns complete thread starting from the leaf (removed comment) till the root (post)\n",
        "# using the above 2 function\n",
        "\n",
        "def find_parent(com, level, parent_dict):\n",
        "  result = parent_dict\n",
        "\n",
        "  if com['parent_id'] == com['link_id']:\n",
        "    try:\n",
        "      sub_dict = find_parent_post(com['parent_id'][3:])\n",
        "      result[level] = [\"Level \"+str(level), \"Parent Post\", sub_dict]\n",
        "      return result\n",
        "    except Exception as e:\n",
        "      print(\"Post ERROR: \", e)\n",
        "      print(\"Comment number:\" + com['id'])\n",
        "  else:\n",
        "    try:\n",
        "      com_dict = find_parent_com(com['parent_id'][3:])\n",
        "      result[level] = [\"Level \"+str(level), \"Parent comment\", com_dict]\n",
        "      level = level +1\n",
        "\n",
        "      find_parent(com_dict, level, result)\n",
        "    except Exception as e:\n",
        "      print(\"Comment ERROR: \", e)\n",
        "      print(\"Comment number:\" + com['id'])\n",
        "  return result"
      ],
      "id": "_rSUnS5Xn6lc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating threads using the above function and Saving in JSON format\n",
        "**Note:** This step takes a lot of time so maeke sure you run. Check the output file name in the cell before running."
      ],
      "metadata": {
        "id": "-bbozPrXBklz"
      },
      "id": "-bbozPrXBklz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining **timestamp** and **output file name tag** used for all files that would be downloaded during this process.\n",
        "\n",
        "**DO NOT** forget to set the subreddit correctly"
      ],
      "metadata": {
        "id": "PbPNBFgNeaAh"
      },
      "id": "PbPNBFgNeaAh"
    },
    {
      "cell_type": "code",
      "source": [
        "# IMP NOTE see if the subreddit is set correctly.\n",
        "subreddit = '_france_'\n",
        "\n",
        "# example for 15th August 2022\n",
        "date1 = datetime(2022,8,15)\n",
        "date2 = datetime.today() #Because com_stream csv loaded above was downloaded from server today\n",
        "\n",
        "dates_str = str(date1.date().strftime('%d%b%Y'))+'_to_'+str(date2.date().strftime('%d%b%Y'))\n",
        "\n",
        "out_file_name_tag = subreddit+dates_str\n",
        "print(out_file_name_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zQATr8JeYyK",
        "outputId": "5e94367e-66ae-4e02-d2e6-e69b723ef8af"
      },
      "id": "-zQATr8JeYyK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_france_15Aug2022_to_28Aug2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLuvRCN2xZZW"
      },
      "outputs": [],
      "source": [
        "# For each comment in removed_com dataframe, call the find_parent function to generate the threads corresponding to that commnet\n",
        "# Check the file name and dates before running this cell\n",
        "\n",
        "result_json = {}\n",
        "temp_list = []\n",
        "counter = 1\n",
        "\n",
        "for idx, com in removed_com.iterrows():\n",
        "  print(\"-----count: \", counter)\n",
        "  temp = {}\n",
        "  x = find_parent(com, 1, temp)\n",
        "  \n",
        "  com_dict = com.to_dict()\n",
        "  com_dict['removed'] = 0 if com_dict['removed'] == False else 1\n",
        "  final_thread = {0: [\"Level 0\", \"Removed comment\", com_dict], **x}\n",
        "  \n",
        "  temp_list.append(final_thread)\n",
        "  # print(\"RESULT: \", final_thread)\n",
        "  counter +=1\n",
        "\n",
        "  # if counter>5:\n",
        "  #   break;\n",
        "  # else:\n",
        "  #   pass\n",
        "\n",
        "result_json['result'] = temp_list\n",
        "\n",
        "f_name = \"initial_detailed_threads\"+out_file_name_tag+'.json'\n",
        "print(f_name)\n",
        "\n",
        "with open(f_name, \"w\") as outfile:\n",
        "    json.dump(result_json, outfile)\n",
        "\n",
        "files.download(\"/content/\"+f_name)"
      ],
      "id": "WLuvRCN2xZZW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeVZIvnkRdBm",
        "outputId": "191deb3c-1042-4594-c453-6d0387954972"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "655"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(temp_list)"
      ],
      "id": "eeVZIvnkRdBm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSD9NELPQwnR"
      },
      "source": [
        "# **Sorting the threads** root---->leaf"
      ],
      "id": "RSD9NELPQwnR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6AD_dTLz1IV"
      },
      "outputs": [],
      "source": [
        "# in case the notebook timeouts, load the json file from your downloads folder\n",
        "# IMP load file from your downloads folder\n",
        "\n",
        "f = open(\"/content/initial_detailed_threads_france_15Aug2022_to_28Aug2022.json\")\n",
        "json_file = json.load(f)"
      ],
      "id": "m6AD_dTLz1IV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlS5fciW0U00"
      },
      "outputs": [],
      "source": [
        "final = []\n",
        "for discussion_dict in json_file['result']:\n",
        "  # print(discussion_dict)\n",
        "  discussion_dict = {int(k): v for k,v in discussion_dict.items()}\n",
        "  sorted_dict = dict(sorted(discussion_dict.items(), reverse=True))\n",
        "  new_dict = {}\n",
        "  i = 0\n",
        "  for k,v in sorted_dict.items():\n",
        "    new_dict[i] = v[2]\n",
        "    i+=1\n",
        "  # print(new_dict)\n",
        "  final.append(new_dict)\n",
        "\n",
        "final_json = {}\n",
        "final_json['result'] = final"
      ],
      "id": "hlS5fciW0U00"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving json file"
      ],
      "metadata": {
        "id": "TXjYrye-if90"
      },
      "id": "TXjYrye-if90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uwBj3AX_UgX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50e46259-811c-4003-f51b-ae1cd48f51ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sorted_detailed_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab8080b3-0581-4951-aab0-3ac5784ac023\", \"sorted_detailed_threads_france_15Aug2022_to_28Aug2022.json\", 2219009)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# save the sorted threads if required\n",
        "sorted_f_name = \"sorted_detailed_threads\"+out_file_name_tag+'.json'\n",
        "print(sorted_f_name)\n",
        "\n",
        "with open(sorted_f_name, \"w\") as outfile:\n",
        "    json.dump(final_json, outfile)\n",
        "\n",
        "files.download(\"/content/\"+sorted_f_name)"
      ],
      "id": "2uwBj3AX_UgX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOEubqZ1Q73_"
      },
      "source": [
        "# **Threads for verification with only author, text, permalink, removed attr**"
      ],
      "id": "zOEubqZ1Q73_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31eMSBX6zK9V"
      },
      "outputs": [],
      "source": [
        "final[0]"
      ],
      "id": "31eMSBX6zK9V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAog8GoGBUfk"
      },
      "outputs": [],
      "source": [
        "# Generating author text permalink threads respectively for post and comments\n",
        "author_text = []\n",
        "\n",
        "for item in final:\n",
        "  dis ={}\n",
        "  for k,v in item.items():\n",
        "    # print(k,v)\n",
        "    if int(k) == 0:\n",
        "      # this is a post\n",
        "      dis[k] = {\"speaker_id\" : v['darma_author'], \"text\" : v['title'] +' '+ v['selftext'] if str(v['selftext']) != 'nan' else v['title'], \"permalink\": v['permalink']}\n",
        "    else:\n",
        "      dis[k] = {\"speaker_id\": v['darma_author'] , \"text\": v['body'], \"permalink\": v['permalink'], \"removed\": v['removed']}\n",
        "  # print(\"\\n\")\n",
        "  author_text.append(dis)"
      ],
      "id": "xAog8GoGBUfk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2UtR6Jcz2Zf"
      },
      "outputs": [],
      "source": [
        "author_text[0]"
      ],
      "id": "r2UtR6Jcz2Zf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEDjZzWYREr8",
        "outputId": "5d167c95-c5d9-4703-ace0-93106cbb8448"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "655"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(author_text)"
      ],
      "id": "TEDjZzWYREr8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving json file"
      ],
      "metadata": {
        "id": "mQIE2dLsinFi"
      },
      "id": "mQIE2dLsinFi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3EiGmDxEb_V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4aff2283-7b32-4426-aac0-9214fe1ed84e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verify_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a49bbb50-6df0-4e91-b40d-d2125499487e\", \"verify_threads_france_15Aug2022_to_28Aug2022.json\", 1697711)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#save and download the files\n",
        "author_text_json = {}\n",
        "author_text_json['result'] = author_text\n",
        "\n",
        "verify_f_name = \"verify_threads\"+out_file_name_tag+'.json'\n",
        "print(verify_f_name)\n",
        "\n",
        "with open(verify_f_name, \"w\") as outfile:\n",
        "    json.dump(author_text_json, outfile)\n",
        "\n",
        "files.download(\"/content/\"+verify_f_name)"
      ],
      "id": "C3EiGmDxEb_V"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3czeFF_uAO1L"
      },
      "source": [
        "**Display**"
      ],
      "id": "3czeFF_uAO1L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBk-_vuLAYoa"
      },
      "outputs": [],
      "source": [
        "# for threads in author_text[:10]:\n",
        "#   for k,v in threads.items():\n",
        "#     print(k,v)\n",
        "#   print('\\n')"
      ],
      "id": "sBk-_vuLAYoa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVnFDofhRmpj"
      },
      "source": [
        "# **Filter threads by toxic author repetition**"
      ],
      "id": "vVnFDofhRmpj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0s3z9jzS4d6",
        "outputId": "e5919ff0-b3dc-4124-b2e0-6fc9316e5c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "655"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "len(author_text)"
      ],
      "id": "l0s3z9jzS4d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7QNAuzwaXk9"
      },
      "outputs": [],
      "source": [
        "# function that returns true/false based on the frequency of toxic author in a thread\n",
        "\n",
        "def repeated_tox_author(thread):\n",
        "  # print(\"thread of len:\", len(thread), thread)\n",
        "  tox_author = list(thread.values())[-1]['speaker_id']\n",
        "  all_authors = {}\n",
        "\n",
        "  for k,v in thread.items():\n",
        "    # print(k,v)\n",
        "    temp_key = v['speaker_id']\n",
        "    all_authors[temp_key] = all_authors.get(temp_key,0) + 1\n",
        "\n",
        "  keep = True if all_authors[tox_author]>1 else False\n",
        "  # print(\"authors freq: \", all_authors)\n",
        "  # print(\"toxic author: \", tox_author, \"freq: \", all_authors[tox_author])\n",
        "  # print(\"keep thread: \", keep)\n",
        "  # print(\"\\n\")\n",
        "\n",
        "  return keep"
      ],
      "id": "u7QNAuzwaXk9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48ULjmLvPtl8"
      },
      "outputs": [],
      "source": [
        "# filtering the threads using above funciton\n",
        "filtered_by_author = []\n",
        "for thread in author_text:\n",
        "  if repeated_tox_author(thread):\n",
        "    filtered_by_author.append(dict(conversation = list(thread.values()), target_user = list(thread.values())[-1]['speaker_id']))"
      ],
      "id": "48ULjmLvPtl8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GdwsEUNcbCl",
        "outputId": "9ed44385-1503-4e46-e90e-5961c4f81d79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "253"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(filtered_by_author)"
      ],
      "id": "7GdwsEUNcbCl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXRri3aizrL_"
      },
      "outputs": [],
      "source": [
        "#display\n",
        "for threads in filtered_by_author[:10]:\n",
        "  conv = threads['conversation']\n",
        "  for i in conv:\n",
        "    print(i)\n",
        "  print('\\n')"
      ],
      "id": "VXRri3aizrL_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving json file"
      ],
      "metadata": {
        "id": "Ox_okgHnjAE-"
      },
      "id": "Ox_okgHnjAE-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvAIKMUx8Kq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97fca6c6-42c8-4b5b-cd75-5df963f2d8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tox_author_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_22762121-d296-49b0-9c69-27f850a5a86c\", \"tox_author_threads_france_15Aug2022_to_28Aug2022.json\", 1054056)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filtered_by_author_json = {}\n",
        "filtered_by_author_json['result'] = filtered_by_author\n",
        "\n",
        "tox_author_f_name = \"tox_author_threads\"+out_file_name_tag+'.json'\n",
        "print(tox_author_f_name)\n",
        "\n",
        "with open(tox_author_f_name,'w') as outfile:\n",
        "  json.dump(filtered_by_author_json, outfile) \n",
        "\n",
        "files.download(\"/content/\"+tox_author_f_name)"
      ],
      "id": "rvAIKMUx8Kq7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y15EHIDT6Ozi"
      },
      "source": [
        "# **Filter out the gaps-- \"Removed and Not Found\"**"
      ],
      "id": "y15EHIDT6Ozi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mFUMhQa6OJp"
      },
      "outputs": [],
      "source": [
        "without_gap = []\n",
        "count = 0\n",
        "\n",
        "for threads in filtered_by_author:\n",
        "  conv = threads['conversation']\n",
        "  flag = 0\n",
        "  for i in conv:\n",
        "    # print(i)\n",
        "    if i['text'] == \"[removed] and NOT FOUND\":\n",
        "      flag = 1\n",
        "      break\n",
        "\n",
        "  # print('flag: ', flag)  \n",
        "  if flag == 1:\n",
        "    pass\n",
        "  else:\n",
        "    without_gap.append(threads)\n",
        "    count+=1\n",
        "  # print(count, '\\n')"
      ],
      "id": "2mFUMhQa6OJp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPnzZ-s3Eyq1",
        "outputId": "1a9117b5-7c41-4572-c09f-8026ba7b3af3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(without_gap)"
      ],
      "id": "ZPnzZ-s3Eyq1"
    },
    {
      "cell_type": "code",
      "source": [
        "for threads in without_gap[:5]:\n",
        "  conv = threads['conversation']\n",
        "  for i in conv:\n",
        "    print(i)\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "ipeBExY6cNUu"
      },
      "id": "ipeBExY6cNUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for threads in without_gap:\n",
        "  for i in threads['conversation']:\n",
        "    # print(i)\n",
        "    if i['text']==\"[deleted]\":\n",
        "      threads['conversation'].remove(i)\n",
        "      print(i)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  # print('flag: ', flag)  \n",
        "  # if flag == 1:\n",
        "  #   pass\n",
        "  # else:\n",
        "  #   without_gap.append(threads)\n",
        "  #   count+=1\n",
        "  # print(count, '\\n')"
      ],
      "metadata": {
        "id": "YQ8U2mauckWD"
      },
      "id": "YQ8U2mauckWD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(without_gap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op7Fz-a7pZ1v",
        "outputId": "4270f525-0651-4385-bfef-0f1396bc750b"
      },
      "id": "Op7Fz-a7pZ1v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving json file"
      ],
      "metadata": {
        "id": "U1kJ9JyUjD0t"
      },
      "id": "U1kJ9JyUjD0t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7DLmHJR7EK9m",
        "outputId": "41da8af3-2f06-45c9-e65a-c415a2a03d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without_gap_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a6827e18-20f9-462b-9e27-7db94cbb7205\", \"without_gap_threads_france_15Aug2022_to_28Aug2022.json\", 1051809)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "without_gap_json = {}\n",
        "without_gap_json['result'] = without_gap\n",
        "\n",
        "wihtout_gap_f_name = \"without_gap_threads\"+out_file_name_tag+'.json'\n",
        "print(wihtout_gap_f_name)\n",
        "\n",
        "with open(wihtout_gap_f_name,'w') as outfile:\n",
        "  json.dump(without_gap_json, outfile)\n",
        "\n",
        "files.download(\"/content/\"+wihtout_gap_f_name)"
      ],
      "id": "7DLmHJR7EK9m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGJJkc0h8Lxg"
      },
      "source": [
        "# **Filter by langID**\n",
        "**Note**: for **french** use lang='fr', for **english** use lang='en'"
      ],
      "id": "hGJJkc0h8Lxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcMOfqzw_uyx"
      },
      "outputs": [],
      "source": [
        "pip install langid"
      ],
      "id": "vcMOfqzw_uyx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRsv30Pe_tHh"
      },
      "outputs": [],
      "source": [
        "import langid\n",
        "from langid.langid import LanguageIdentifier, model\n",
        "\n",
        "identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
        "\n",
        "#checking if the thread is of a particular lang\n",
        "def check_thread_language(thread, lang):\n",
        "  thread_len = len(thread['conversation'])\n",
        "\n",
        "  class_list = []\n",
        "  for com in thread['conversation']:\n",
        "    # print(\">>>comment: \", com)\n",
        "    class_list.append(identifier.classify(com['text'])[0])\n",
        "\n",
        "  count_fr = class_list.count(lang)\n",
        "  is_french = count_fr > thread_len/2\n",
        "\n",
        "  # print(class_list, count_fr, thread_len, is_french)\n",
        "  return is_french\n",
        "\n",
        "# print(identifier.rank(input3)[:3])"
      ],
      "id": "jRsv30Pe_tHh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: for **french** use lang='fr', for **english** use lang='en'"
      ],
      "metadata": {
        "id": "ChYXLU6MrjvE"
      },
      "id": "ChYXLU6MrjvE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrKZNRsr8TRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b23edd5-0c11-4b1d-c341-f18310cec097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count:  242\n"
          ]
        }
      ],
      "source": [
        "selected_count = 0\n",
        "filtered_by_lang = []\n",
        "not_selected = []\n",
        "\n",
        "#IMP read note\n",
        "for thread in without_gap:\n",
        "  keep = check_thread_language(thread,lang = 'fr')\n",
        "  if keep:\n",
        "    filtered_by_lang.append(thread)\n",
        "    selected_count += 1\n",
        "  else:\n",
        "    not_selected.append(thread)\n",
        "\n",
        "print(\"Count: \", selected_count)"
      ],
      "id": "UrKZNRsr8TRa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf17ciWkfRUe",
        "outputId": "f3c5844a-fb40-4017-eabb-e2cc73c83a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "selected threads:  242\n",
            "not-selected threads:  10\n"
          ]
        }
      ],
      "source": [
        "print(\"selected threads: \", len(filtered_by_lang))\n",
        "print(\"not-selected threads: \", len(not_selected))"
      ],
      "id": "kf17ciWkfRUe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSi7hl_Z1vPX"
      },
      "outputs": [],
      "source": [
        "#thread not selected by langID filter\n",
        "\n",
        "# for item in not_selected:\n",
        "#   print(\"\\n Thread len: \", len(item['conversation']))\n",
        "#   o = check_thread_language(item, lang='fr')\n",
        "#   print(o)"
      ],
      "id": "jSi7hl_Z1vPX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving json file"
      ],
      "metadata": {
        "id": "Lk564cD6jI3B"
      },
      "id": "Lk564cD6jI3B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rYVWvu96MOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4db961f-f7f6-40cb-9e09-da9ff538c251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langID_filter_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8add31a1-923c-4e30-80fa-b345b9e2454b\", \"langID_filter_threads_france_15Aug2022_to_28Aug2022.json\", 1037100)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filtered_by_lang_json = {}\n",
        "filtered_by_lang_json['result'] = filtered_by_lang\n",
        "\n",
        "lang_f_name = \"langID_filter_threads\"+out_file_name_tag+'.json'\n",
        "print(lang_f_name)\n",
        "\n",
        "with open(lang_f_name, \"w\") as outfile:\n",
        "    json.dump(filtered_by_lang_json, outfile)\n",
        "\n",
        "files.download(\"/content/\"+lang_f_name)"
      ],
      "id": "5rYVWvu96MOo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUn0PCwkIWi3"
      },
      "source": [
        "# **Text preprocessing: Removing qouted text, new lines, etc**"
      ],
      "id": "IUn0PCwkIWi3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaHe7bAq174U",
        "outputId": "5a72db85-03dc-41fd-f363-4da5897f812c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bonjour,\\r', '\\r', 'Ce commentaire a été supprimé. Merci de t’exprimer de façon moins agressive.\\r']\n",
            "Bonjour,\r \r Ce commentaire a été supprimé. Merci de t’exprimer de façon moins agressive.\r\n"
          ]
        }
      ],
      "source": [
        "# new_list=['Bonjour,\\r', '\\r', 'Ce commentaire a été supprimé. Merci de t’exprimer de façon moins agressive.\\r']\n",
        "# # new_list = [x.replace('\\r','') for x in new_list]\n",
        "# print(new_list)\n",
        "# # ['Bonjour,\\r', '\\r', 'Ce commentaire a été supprimé. Merci de t’exprimer de façon moins agressive.\\r', '\\r', ' ------------------------ \\r', '\\r', 'This comment has been removed. Please do not be agressive towards other users.\\r', '\\r', '\\r', '\\r', \"Les règles de /r/france sont [disponibles ici](https://www.reddit.com/r/france/wiki/regles). Pour contester cette action, ou pour toute question, merci d'envoyer un [message aux modérateurs](https://www.reddit.com/message/compose?to=%2Fr%2Ffrance).\\r\", '\\r', 'Merci de ta compréhension.']\n",
        "\n",
        "# print(\" \".join(new_list))"
      ],
      "id": "eaHe7bAq174U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0z_6YKQIcCL"
      },
      "outputs": [],
      "source": [
        "for thread in filtered_by_lang:\n",
        "  for com in thread['conversation']:\n",
        "    # print('OLD: ', com['text'])\n",
        "    com_list = com['text'].split('\\n')\n",
        "\n",
        "    new_com_list = [x if x.startswith('>')==False else \"\\n\" for x in com_list]\n",
        "    new_com_list = [x.replace('\\r','') for x in new_com_list]\n",
        "    new_com_list = [x.replace('\\n','') for x in new_com_list]\n",
        "\n",
        "    temp_text = ' '.join(new_com_list)\n",
        "    new_text = ' '.join(temp_text.split())\n",
        "\n",
        "    com['text'] = new_text\n",
        "    \n",
        "    # print(\"NEW: \", com['text'])\n",
        "  # print(\"-------------------------------------------\")"
      ],
      "id": "a0z_6YKQIcCL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdeGiUo1MBa-",
        "outputId": "25f38fbf-7745-45d5-e59d-21ee7b4727f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(filtered_by_lang)"
      ],
      "id": "ZdeGiUo1MBa-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--vJOTrDVYLW"
      },
      "outputs": [],
      "source": [
        "for i in filtered_by_lang[:2]:\n",
        "  for com in i['conversation']:\n",
        "    print(com['text'])\n",
        "  print(\"--------------------------------\")"
      ],
      "id": "--vJOTrDVYLW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving json file"
      ],
      "metadata": {
        "id": "vfc7V_EbjNoJ"
      },
      "id": "vfc7V_EbjNoJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhcBeEZ8WELb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4fc4ab47-2c35-436a-deb0-5fb94492c075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fltr_clean_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_253e13f8-20e4-4049-a02b-7cd840c0676a\", \"fltr_clean_threads_france_15Aug2022_to_28Aug2022.json\", 950894)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filtered_clean_f_name = \"fltr_clean_threads\"+out_file_name_tag+'.json'\n",
        "print(filtered_clean_f_name)\n",
        "\n",
        "with open(filtered_clean_f_name, 'w') as op_f:\n",
        "  json.dump(filtered_by_lang, op_f)\n",
        "\n",
        "files.download(\"/content/\"+filtered_clean_f_name)"
      ],
      "id": "rhcBeEZ8WELb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final format (Text and speaker_id)**"
      ],
      "metadata": {
        "id": "ftG9ZXmxtaBP"
      },
      "id": "ftG9ZXmxtaBP"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in filtered_by_lang[:2]:\n",
        "  for com in i['conversation']:\n",
        "    print(json.dumps(com, indent=1))\n",
        "  print(\"--------------------------------\")"
      ],
      "metadata": {
        "id": "7ikvXAwStg4e"
      },
      "id": "7ikvXAwStg4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in filtered_by_lang:\n",
        "  t_temp=[]\n",
        "  for com in i['conversation']:\n",
        "    com = {k:v for k,v in com.items() if k in ['speaker_id', 'text']}\n",
        "    t_temp.append(com)\n",
        "  i['conversation'] = t_temp\n",
        "    # print(json.dumps(com, indent=1))\n",
        "  # print(\"--------------------------------\")"
      ],
      "metadata": {
        "id": "gwLjsSgFuuZe"
      },
      "id": "gwLjsSgFuuZe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in filtered_by_lang[:2]:\n",
        "  for com in i['conversation']:\n",
        "    print(json.dumps(com, indent=1))\n",
        "  print(\"--------------------------------\")"
      ],
      "metadata": {
        "id": "VA93D9HFV7__"
      },
      "id": "VA93D9HFV7__",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_f_name = \"protocol_threads\"+out_file_name_tag+'.json'\n",
        "print(final_f_name)\n",
        "\n",
        "with open(final_f_name,'w') as opf:\n",
        "  json.dump(filtered_by_lang, opf)\n",
        "\n",
        "files.download('/content/'+final_f_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R5PxrnpS3d9B",
        "outputId": "289ab2e4-733e-4341-b8bc-29bc014d2c90"
      },
      "id": "R5PxrnpS3d9B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protocol_threads_france_15Aug2022_to_28Aug2022.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcf03671-0a84-453d-9b41-02570d743a58\", \"protocol_threads_france_15Aug2022_to_28Aug2022.json\", 772928)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UaVF9TqNV3LX"
      },
      "id": "UaVF9TqNV3LX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D1kxeTvD2nL2",
        "noW-TRbOapZ8",
        "Zy7F1LvtBVFD"
      ],
      "name": "thread_generation_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}